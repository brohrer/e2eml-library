<!DOCTYPE html>
<html>

  <script type="text/javascript">var blog_title = "Machine learning resources";</script>
  <script type="text/javascript">var publication_date = "November 16, 2020";</script>
  <head>
    <link rel="icon" href="images/ml_logo.png">
    <meta charset='utf-8'>
    <meta name=viewport content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">
    <base target="_blank">
    <script type="text/javascript" src="javascripts/blog_head.js"></script>
  </head>
  <body>
    <script type="text/javascript" src="javascripts/blog_header.js"></script>
    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        
        <p>
          If you want to study machine learning but don't have the luxury of
          attending university full-time, you're in luck.
          There is a wonderfully rich collection of courses, posts, videos,
          notebooks, and tutorials online. There is so much, in fact, that
          it can be hard to know where to start.
          I put together this guide
          as a starting place, a first foothold for anyone who wants
          to jump in.
        </p>
        <p>
          To pull together these recommendations, I sent out a call for help
          on
          <a href="https://www.linkedin.com/posts/brohrer_hey-machine-learning-connections-ive-been-activity-6733150782885044224-1goC">
            LinkedIn</a> and
          <a href="https://twitter.com/_brohrer_/status/1327385351875403778?s=20">
            Twitter</a>.
          The replies show not just how much is out there, but how
          passionate people are about the teachers that helped a concept click
          for them. (Thank you to all of you who added your recommendations!)
        </p>
        <p>
          Here are some hand-picked short lists. I have a few other lists
          of relevant background topics, like
          <a href="python_resources.html">learning Python</a>,
          <a href="linear_algebra_resources.html">linear algebra</a>, and
          <a href="statistics_resources.html">statistics</a>,
          but those listed here focus on the core concepts
          of machine learning (ML).
        </p>

        <h3>Getting started</h3>
        <p>
          <strong>Josh Starmer's
          <a href="https://statquest.org/">Statquest</a></strong>
          is a playfully narrated video series covering a remarkably broad
          set of ML concepts. They're free, but if you're in a
          position to do so,
          <a href="https://statquest.org/support-statquest/">
            consider donating to the cause</a>.
        </p>
        <p>
          <strong><a href="https://machinelearningflashcards.com/">
            Machine Learning Flash Cards</a> from Chris Albon</a></strong>
          do a beautiful job of slicing through the language barrier
          between English and ML-ese. One by one, they break down terms and
          concepts into easy to digest illustrated explanations. The
          complete set is $12 USD, but Chris has a standing offer that
          you can <a href="https://chrisalbon.com/about/chris_albon/">
            contact him</a> and request a set for free for any reason,
          no questions asked.
        </p>
        <p>
          <strong><a href="https://www.manning.com/books/grokking-machine-learning">
            Grokking Machine Learning</a> is a hot off the presses book by
          Luis Serrano</strong> covering a textbook's worth of ML using
          concrete examples and a delightfully accessible style. (e2eML
          readers can help themselves to 40% discount off all formats of the
          books with the code <strong>serranopc</strong>.)
          
        </p>
        <p>
          Among the legendary math videos of <strong>
          3 Blue 1 Brown, a.k.a. Grant Sanderson, is
          <a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi">
            a neural networks series</a></strong> that helps to build a
          strong intuition for how they work without watering down
          any of the math.
        </p>

        <h3>Going deep</h3>
        <p>
          There are two books that are similar in scope in approach:
          <strong>Aur√©lien Geron's
          <a href="https://homl.info/get/">
          Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow</a>
          </strong> and 
          <strong>
          <a href="https://sebastianraschka.com/books.html#python-machine-learning-3rd-edition">
            Python Machine Learning</a> by Sebastian Raschka
          and Vahid Mirjalili</strong>. Both contain ML examples from all across
          the Python toolset, using NumPy, Scikit-Learn, and TensorFlow to cover
          all the most common learning methods. All the code examples and
          notebooks from both are generously provided in public GitHub
          repositories
          (<a href="https://github.com/rasbt/python-machine-learning-book-3rd-edition">PML code</a>,
          <a href="https://github.com/ageron/handson-ml2">
            HOML code</a>). And both come warmly recommended by a large number
          of readers. But they aren't identical. Their differences in coverage and
          voice make them excellent complements.
        </p>
        <p>
          <strong>Andrew Ng's
          <a href="https://www.coursera.org/learn/machine-learning">
            classic machine learning course</a></strong> was
          mentioned more often than any other resource.
        </p>
        <p>
          If you're mainly focused on neural networks, there are a pair of
          resources you might find useful: 
          <strong><a href="https://www.fast.ai/">fast.ai</a> courses, taught by 
          Jeremy Howard, Rachael Thomas, and Sylvain Gugger</strong>,
          and <strong>
          <a href="https://www.youtube.com/playlist?list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC">
            Stanford's CS231n lectures from Winter 2016</a>
          taught by Andrej Karpathy and
          <a href="https://www.youtube.com/playlist?list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk">
            Spring 2017</a> taught by Fei-Fei Li, Justin Johnson,
          and Serena Yeung</strong>. They differ widely in their presentation,
          but the different viewpoints work in stereo to create a rich
          view of the topic.
        </p>


        <h3>Reference</h3>
        <p>
          The resources in this section are dense enough that they can 
          be challenging to absorb the first time through. However,
          once you have a grounding in the concepts, their
          concise summaries and insightful derivations can
          refresh your memory or deepen your understanding.
        </p>
        <p>
          <strong><a href"https://web.stanford.edu/~hastie/ElemStatLearn/">
          The Elements of Statistical Learning</a>
          by Trevor Hastie, Robert Tibshirani, and Jerome Friedman</strong>
          is a widely loved classic. Its presentation is dense, but thorough.
          The authors offer a PDF version for free.
        </p>
        <p>
          <strong>Andriy Burkov's <a href="http://themlbook.com/">
            Hundred Page Machine Learning Book</a></strong> makes ML
            extremely accessible. It provides concise descriptions of a wide
            variety of techniques. It's now availble in 11 languages.
        </p>

        <h3>Pushing the edge</h3>
        <p>
          If you are looking for advanced instruction on machine learning,
          you will have no choice but to <strong>read reseach papers</strong>.
          One exciting (or maddening, depending on who you ask) part of
          working in such a young field is that the advanced material is still
          taking shape. There isn't yet general
          relativity-level theory. It's a free-for-all. The only
          way to keep up with the latest developments is to choose a couple
          areas of interest and keep an eye out for papers in that area.
        </p>
        <p>
          Even reading papers will only keep you on top of work that has
          already been done. To expand the frontiers of machine learning there
          is no substitute for <strong>solving practical problems</strong>
          with machine learning, questions that someone outside the field might
          want to know the answer to. It's tough to come up with approaches
          that have never been tried, but it's surprisingly easy to
          find problems to which ML has never been successfully applied.
          As soon as you have a concrete goal, the details of your problem
          will push your method to its limits and, more often than not,
          force you to adapt or extend it. It is an excellent way to
          distinguish yourself in a crowded field of competent practitioners.
        </p>
        <br>
        <br>
        <p>
          I'm stopping here, because a list's value is inversely proportional
          to it's length, but these are only a starting point.
          There are many other fantastic resources for learning ML
          online. A quick look at the original
          <a href="https://www.linkedin.com/posts/brohrer_hey-machine-learning-connections-ive-been-activity-6733150782885044224-1goC">
            LinkedIn</a> and
          <a href="https://twitter.com/_brohrer_/status/1327385351875403778?s=20">
            Twitter</a> replies will show just how deep the bench is.
          It doesn't matter where you start, as long as you start.
          Pour some tea, click a link, and dive in.
        </p>


        <script type="text/javascript" src="javascripts/blog_signature.js"></script>
      </section>
    </div>
    <script type="text/javascript" src="javascripts/blog_footer.js"></script>
  </body>
</html>
