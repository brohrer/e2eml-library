<!DOCTYPE html>
<html>
  <head>
    <link rel="icon" href="images/ml_logo.png">
    <meta charset='utf-8'>
    <meta name=viewport content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Brandon Rohrer: e2eML Laboratory">
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">
    <base target="_blank">
    
    <title>Research</title>
    </head>

  <body>
    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <h1 id="project_title">
              Research Lab
          </h1>
          <h4>
            <a href="https://e2eml.school">Brandon Rohrer</a>
          </h4>
        </header>
    </div>
    
    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <p>
          Here are some things I've made &mdash; algorithms, methods,
          packages &mdash; of which I'm particularly proud. As far as I know
          they are novel, but I haven't done deep literature searches to
          find out for sure.
        </p>
        <hr>
	      <a href="https://e2eml.school/knn_adaptive_feature_weighting.html"> 
        <h3><em>k</em>-nearest neighbors adaptive feature weighting</h3></a>
        <p>
          <em>k</em>-nearest neighbors is remarkably powerful right out of the box with the exception that it can be sensitive to how features are weighted.
          Feature weighting accounts for the fact that some features can be much more important than others. 
          Getting these weights just right can be labor intensive.
          This method finds them automatically through an optimization 
          similar to Powell's method. 
        </p>

	      <a href="https://e2eml.school/knn_data_reduction.html">
        <h3><em>k</em>-nearest neighbors data reduction</h3></a>
        <p>
          To keep <em>k</em>-nearest neighbors running quickly,
          it's helpful to limit the number of points retained.
          One way to to do that is to randomly select a subset of the
          observations to keep as training points. Another is to try
          to cover the space more efficiently, getting the same level of
          accuracy with fewer points.
          <a href="https://e2eml.school/knn_data_reduction.html">
          This is a one scheme for that.</a>
        </p>

	      <a href="https://e2eml.school/k_sparse_layer.html"> 
        <h3><em>k</em>-sparse neural network layer</h3></a>
        <p style="text-align:center;">
          <img title="The output representation of a few nodes from the hidden sparse layer"
            src="images/sparsify/sparse_hidden_layer.png"
            alt="The output representation of a few nodes from the hidden sparse layer"
            style="height: 320px;">
        </p>
        <p>
          <a href="https://arxiv.org/pdf/1312.5663.pdf">
            <em>k</em>-sparse autoencoders</a>
          were originally developed and presented by Alireza Makhzani
          and Brendan Frey.
          In a <em>k</em>-sparse layer, only the <em>k</em> nodes with highest
          magnitude activity are allowed to keep their activity on a given
          iteration. All others are set to zero. It results in hidden
          nodes with identifiable structure.
          The only part of my implementation
          I believe is new is the addition of
          an adaptive sensitivity term to facilitate training.
          <a href="https://e2eml.school/k_sparse_layer.html">
            Here's more on how it works and how to use it.
          </a>
	      </p>

        <h3>Evolutionary Powell's method</h3>
        <p style="text-align:center;">
          <img
            alt="Animation of Evolutionary Powell's method finding an optimum"
            src="https://gitlab.com/brohrer/ponderosa/raw/master/ponderosa/landing_page_demo.gif"
            style="height: 350px;">
        </p>
        <p>
          I built Evolutionary Powell's method as a hyperparameter optimization
          algorithm as part of
          <a href="https://end-to-end-machine-learning.teachable.com/p/314-neural-network-optimization/">
            Course 314</a>. It is inspired by the original
          <a href="https://en.wikipedia.org/wiki/Powell%27s_method">
            Powell's method</a>, but has a stochastic element
          inspired by
          <a href="https://en.wikipedia.org/wiki/Evolutionary_algorithm">
            evolutionary approaches</a>.
          <a href="https://e2eml.school/evopowell.html">
            Here's more information on how it works and how to use it.
          </a>
        </p>

        <a id="pathfinder"></a>
        <h3>Pathfinder</h3>
        <p style="text-align:center;">
          <img
            src="https://engineering.fb.com/wp-content/uploads/2019/01/CodeBlogEnergy_Model.gif"
            style="height: 350px;">
            <br>
            Animation of the Pathfinder algorithm in action, finding power
            lines in the region of Kano, Nigeria.
            <!--src="https://raw.githubusercontent.com/carderne/gridfinder/master/gridfinder-animated.gif"
          Animation of the Chris Arderne's implementation of the algorithm
          in action, finding power lines in Uganda.-->
        </p>
        <p>
          <a href="https://github.com/facebookresearch/many-to-many-dijkstra">
            Pathfinder</a> is a many-to-many variant of
            <a href="https://en.wikipedia.org/wiki/Dijkstra's_algorithm">
              Dijkstra's shortest path algorithm</a>.
            I got to work on it while at Facebook when I was
            <a href="https://engineering.fb.com/connectivity/electrical-grid-mapping/">
              trying to predict the locations of medium-voltage
            electrical distribution grid infrastructure</a>. It's based
            entirely on publicly
            available data sources, including nighttime satellite imagery
            and Open Street Map highways. Here's
            <a href="https://github.com/facebookresearch/many-to-many-dijkstra/blob/master/Model%20Tutorial%20-%20PDF.pdf">
              a tutorial on how it works and how to re-create it</a>.
        </p>
        <p>
          Chris Arderne did an improved re-implementation, called
          <a href="https://github.com/carderne/gridfinder">
            GridFinder</a> which has been used by the World Bank and
          its partners to estimate the location of medium voltage
          power grids throughout Africa, and then through the rest
          of the world.
        </p>

    </div>

      
    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <section class="clearfix">
          <h2 id="project_tagline">
            <a id="project_tagline" href="blog.html">
              <span>Visit the e2eML library</span></a>
          </h2>
          <p>
            <br>
            <a href="https://creativecommons.org/publicdomain/zero/1.0/">
              <img title="Creative Commons Zero license" src="images/cc0.png" alt="CC0" style="width: 90px;" />
            </a> &nbsp except where noted.
          </p>
          <p>
            The postings on this site are my own and don't necessarily represent iRobot's
            positions, strategies or opinions.
          </p>
         </section>
      </footer>
    </div>
  </body>
</html>
